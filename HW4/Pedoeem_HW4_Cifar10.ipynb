{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aCuSUppRWb1-"
   },
   "source": [
    "## Jonathan Pedoeem\n",
    "## Prof. Curro HW4 CIFAR10\n",
    "## October 4th, 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NqDYFTzHWb2A"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gmk-LBHYWb2D"
   },
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "tf.set_random_seed(1234)\n",
    "IMAGE_HEIGHT = 32\n",
    "IMAGE_WIDTH  = 32\n",
    "IMAGE_DEPTH = 3\n",
    "batch_size = 20\n",
    "NUM_CLASSES = 10\n",
    "l2_lamb = 1e-3\n",
    "lr = 1e-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TaTGI__fWb2F"
   },
   "outputs": [],
   "source": [
    "def reshape(x):\n",
    "    return np.reshape(x, [-1,IMAGE_WIDTH,IMAGE_HEIGHT,IMAGE_DEPTH])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PoxhEm9wWb2I"
   },
   "outputs": [],
   "source": [
    "def get_cifar10():\n",
    "    datum = {}\n",
    "    cifar10 = tf.keras.datasets.cifar10\n",
    "    (x_train, y_train),(x_test, y_test) = cifar10.load_data()\n",
    "    x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "    randos = np.random.choice(50000,50000,replace=False)\n",
    "    validation_randos = randos[:10000]\n",
    "    train_randos = randos[10000:]\n",
    "    val_x, val_y = reshape(x_train[validation_randos]), y_train[validation_randos]\n",
    "    x_train, y_train = reshape(x_train[train_randos]), y_train[train_randos]\n",
    "    x_test = reshape(x_test)\n",
    "    y_train = keras.utils.to_categorical(y_train, NUM_CLASSES)\n",
    "    y_test = keras.utils.to_categorical(y_test, NUM_CLASSES)\n",
    "    val_y = keras.utils.to_categorical(val_y,NUM_CLASSES)\n",
    "    datum = {\"x_train\":x_train, \"y_train\":y_train, \"x_val\":val_x, \"y_val\":val_y,\"x_test\":x_test,\"y_test\":y_test}\n",
    "    return datum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "psybCDhpWb2K",
    "outputId": "beae3d79-f80c-4f93-f0e1-5ecb044a8c76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 451s 3us/step\n"
     ]
    }
   ],
   "source": [
    "datum = get_cifar10()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wMuyy20cWb2L"
   },
   "outputs": [],
   "source": [
    "# from keras website\n",
    "datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "    horizontal_flip=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dJWP-KjAWb2N"
   },
   "outputs": [],
   "source": [
    "datagen.fit(datum[\"x_train\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "62k9BakRWb2P"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.BatchNormalization(input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_DEPTH)))\n",
    "model.add(keras.layers.Conv2D(filters=99,kernel_size=(3,3), strides=2,padding='valid',activation='relu',kernel_initializer=keras.initializers.VarianceScaling()))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Dropout(0.35))\n",
    "model.add(keras.layers.Conv2D(filters=99,kernel_size=(3,3),strides=2,padding='valid',activation='relu', kernel_initializer=keras.initializers.VarianceScaling()))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Dropout(0.35))\n",
    "model.add(keras.layers.Conv2D(filters=202,kernel_size=(3,3),strides=1,padding='valid',activation='relu', kernel_initializer=keras.initializers.VarianceScaling()))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Dropout(0.35))\n",
    "model.add(keras.layers.Conv2D(filters=202,kernel_size=(3,3),strides=2,padding='same',activation='relu', kernel_initializer=keras.initializers.VarianceScaling()))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Dropout(0.4))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(NUM_CLASSES,activation=\"softmax\", kernel_initializer=keras.initializers.VarianceScaling()))\n",
    "model.compile(optimizer=keras.optimizers.SGD(lr, momentum=0.7),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 9177
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "r1JbRKuLWb2V",
    "outputId": "14c2ab6d-a8e7-4a8e-af92-c5f5f28438ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      " - 15s - loss: 1.9299 - acc: 0.3502 - val_loss: 2.0973 - val_acc: 0.2548\n",
      "Epoch 2/400\n",
      " - 8s - loss: 1.5463 - acc: 0.4597 - val_loss: 2.2348 - val_acc: 0.2455\n",
      "Epoch 3/400\n",
      " - 8s - loss: 1.4134 - acc: 0.5050 - val_loss: 2.3734 - val_acc: 0.2402\n",
      "Epoch 4/400\n",
      " - 8s - loss: 1.3240 - acc: 0.5353 - val_loss: 2.4009 - val_acc: 0.2841\n",
      "Epoch 5/400\n",
      " - 8s - loss: 1.2411 - acc: 0.5625 - val_loss: 1.8961 - val_acc: 0.4011\n",
      "Epoch 6/400\n",
      " - 8s - loss: 1.1877 - acc: 0.5831 - val_loss: 1.5039 - val_acc: 0.4949\n",
      "Epoch 7/400\n",
      " - 8s - loss: 1.1285 - acc: 0.6020 - val_loss: 1.1861 - val_acc: 0.5839\n",
      "Epoch 8/400\n",
      " - 8s - loss: 1.0879 - acc: 0.6143 - val_loss: 1.1413 - val_acc: 0.6048\n",
      "Epoch 9/400\n",
      " - 8s - loss: 1.0472 - acc: 0.6301 - val_loss: 1.0221 - val_acc: 0.6473\n",
      "Epoch 10/400\n",
      " - 8s - loss: 1.0120 - acc: 0.6422 - val_loss: 0.9589 - val_acc: 0.6658\n",
      "Epoch 11/400\n",
      " - 8s - loss: 0.9915 - acc: 0.6516 - val_loss: 0.8974 - val_acc: 0.6898\n",
      "Epoch 12/400\n",
      " - 8s - loss: 0.9563 - acc: 0.6655 - val_loss: 0.8800 - val_acc: 0.6951\n",
      "Epoch 13/400\n",
      " - 8s - loss: 0.9397 - acc: 0.6675 - val_loss: 0.8831 - val_acc: 0.6909\n",
      "Epoch 14/400\n",
      " - 8s - loss: 0.9194 - acc: 0.6750 - val_loss: 0.8459 - val_acc: 0.7067\n",
      "Epoch 15/400\n",
      " - 8s - loss: 0.8919 - acc: 0.6854 - val_loss: 0.8358 - val_acc: 0.7056\n",
      "Epoch 16/400\n",
      " - 8s - loss: 0.8794 - acc: 0.6887 - val_loss: 0.8297 - val_acc: 0.7114\n",
      "Epoch 17/400\n",
      " - 8s - loss: 0.8558 - acc: 0.6961 - val_loss: 0.7952 - val_acc: 0.7228\n",
      "Epoch 18/400\n",
      " - 8s - loss: 0.8389 - acc: 0.7053 - val_loss: 0.7803 - val_acc: 0.7227\n",
      "Epoch 19/400\n",
      " - 8s - loss: 0.8197 - acc: 0.7114 - val_loss: 0.7611 - val_acc: 0.7300\n",
      "Epoch 20/400\n",
      " - 8s - loss: 0.8076 - acc: 0.7163 - val_loss: 0.7467 - val_acc: 0.7378\n",
      "Epoch 21/400\n",
      " - 8s - loss: 0.7863 - acc: 0.7241 - val_loss: 0.7671 - val_acc: 0.7316\n",
      "Epoch 22/400\n",
      " - 8s - loss: 0.7840 - acc: 0.7242 - val_loss: 0.7357 - val_acc: 0.7433\n",
      "Epoch 23/400\n",
      " - 8s - loss: 0.7666 - acc: 0.7291 - val_loss: 0.7335 - val_acc: 0.7414\n",
      "Epoch 24/400\n",
      " - 8s - loss: 0.7523 - acc: 0.7333 - val_loss: 0.7223 - val_acc: 0.7412\n",
      "Epoch 25/400\n",
      " - 8s - loss: 0.7394 - acc: 0.7364 - val_loss: 0.6992 - val_acc: 0.7513\n",
      "Epoch 26/400\n",
      " - 8s - loss: 0.7325 - acc: 0.7421 - val_loss: 0.7027 - val_acc: 0.7522\n",
      "Epoch 27/400\n",
      " - 8s - loss: 0.7228 - acc: 0.7458 - val_loss: 0.6829 - val_acc: 0.7582\n",
      "Epoch 28/400\n",
      " - 8s - loss: 0.7097 - acc: 0.7473 - val_loss: 0.6950 - val_acc: 0.7516\n",
      "Epoch 29/400\n",
      " - 8s - loss: 0.7037 - acc: 0.7502 - val_loss: 0.6827 - val_acc: 0.7609\n",
      "Epoch 30/400\n",
      " - 8s - loss: 0.6963 - acc: 0.7539 - val_loss: 0.6918 - val_acc: 0.7586\n",
      "Epoch 31/400\n",
      " - 8s - loss: 0.6883 - acc: 0.7549 - val_loss: 0.6769 - val_acc: 0.7622\n",
      "Epoch 32/400\n",
      " - 8s - loss: 0.6819 - acc: 0.7594 - val_loss: 0.6557 - val_acc: 0.7719\n",
      "Epoch 33/400\n",
      " - 8s - loss: 0.6705 - acc: 0.7642 - val_loss: 0.6619 - val_acc: 0.7691\n",
      "Epoch 34/400\n",
      " - 8s - loss: 0.6648 - acc: 0.7658 - val_loss: 0.6626 - val_acc: 0.7719\n",
      "Epoch 35/400\n",
      " - 8s - loss: 0.6530 - acc: 0.7668 - val_loss: 0.6472 - val_acc: 0.7754\n",
      "Epoch 36/400\n",
      " - 8s - loss: 0.6506 - acc: 0.7697 - val_loss: 0.6564 - val_acc: 0.7738\n",
      "Epoch 37/400\n",
      " - 8s - loss: 0.6398 - acc: 0.7746 - val_loss: 0.6321 - val_acc: 0.7807\n",
      "Epoch 38/400\n",
      " - 8s - loss: 0.6375 - acc: 0.7721 - val_loss: 0.6463 - val_acc: 0.7750\n",
      "Epoch 39/400\n",
      " - 8s - loss: 0.6271 - acc: 0.7770 - val_loss: 0.6213 - val_acc: 0.7846\n",
      "Epoch 40/400\n",
      " - 8s - loss: 0.6204 - acc: 0.7818 - val_loss: 0.6373 - val_acc: 0.7785\n",
      "Epoch 41/400\n",
      " - 8s - loss: 0.6157 - acc: 0.7810 - val_loss: 0.6340 - val_acc: 0.7798\n",
      "Epoch 42/400\n",
      " - 8s - loss: 0.6013 - acc: 0.7857 - val_loss: 0.6488 - val_acc: 0.7772\n",
      "Epoch 43/400\n",
      " - 8s - loss: 0.6013 - acc: 0.7871 - val_loss: 0.6085 - val_acc: 0.7898\n",
      "Epoch 44/400\n",
      " - 8s - loss: 0.5975 - acc: 0.7875 - val_loss: 0.6049 - val_acc: 0.7896\n",
      "Epoch 45/400\n",
      " - 8s - loss: 0.5910 - acc: 0.7874 - val_loss: 0.6143 - val_acc: 0.7867\n",
      "Epoch 46/400\n",
      " - 8s - loss: 0.5885 - acc: 0.7914 - val_loss: 0.6109 - val_acc: 0.7893\n",
      "Epoch 47/400\n",
      " - 8s - loss: 0.5759 - acc: 0.7945 - val_loss: 0.6266 - val_acc: 0.7832\n",
      "Epoch 48/400\n",
      " - 8s - loss: 0.5717 - acc: 0.7955 - val_loss: 0.6109 - val_acc: 0.7875\n",
      "Epoch 49/400\n",
      " - 8s - loss: 0.5679 - acc: 0.7976 - val_loss: 0.5944 - val_acc: 0.7958\n",
      "Epoch 50/400\n",
      " - 8s - loss: 0.5660 - acc: 0.7983 - val_loss: 0.5987 - val_acc: 0.7924\n",
      "Epoch 51/400\n",
      " - 8s - loss: 0.5682 - acc: 0.7970 - val_loss: 0.5929 - val_acc: 0.7950\n",
      "Epoch 52/400\n",
      " - 8s - loss: 0.5626 - acc: 0.8005 - val_loss: 0.5845 - val_acc: 0.7974\n",
      "Epoch 53/400\n",
      " - 8s - loss: 0.5516 - acc: 0.8063 - val_loss: 0.5866 - val_acc: 0.7993\n",
      "Epoch 54/400\n",
      " - 8s - loss: 0.5519 - acc: 0.8051 - val_loss: 0.5908 - val_acc: 0.7983\n",
      "Epoch 55/400\n",
      " - 8s - loss: 0.5420 - acc: 0.8075 - val_loss: 0.5808 - val_acc: 0.8014\n",
      "Epoch 56/400\n",
      " - 8s - loss: 0.5364 - acc: 0.8091 - val_loss: 0.5745 - val_acc: 0.8047\n",
      "Epoch 57/400\n",
      " - 8s - loss: 0.5303 - acc: 0.8109 - val_loss: 0.5771 - val_acc: 0.7996\n",
      "Epoch 58/400\n",
      " - 8s - loss: 0.5232 - acc: 0.8139 - val_loss: 0.5946 - val_acc: 0.7948\n",
      "Epoch 59/400\n",
      " - 8s - loss: 0.5309 - acc: 0.8097 - val_loss: 0.5820 - val_acc: 0.7990\n",
      "Epoch 60/400\n",
      " - 8s - loss: 0.5258 - acc: 0.8130 - val_loss: 0.6156 - val_acc: 0.7893\n",
      "Epoch 61/400\n",
      " - 8s - loss: 0.5218 - acc: 0.8128 - val_loss: 0.5748 - val_acc: 0.8040\n",
      "Epoch 62/400\n",
      " - 8s - loss: 0.5168 - acc: 0.8152 - val_loss: 0.5816 - val_acc: 0.8005\n",
      "Epoch 63/400\n",
      " - 8s - loss: 0.5135 - acc: 0.8168 - val_loss: 0.5671 - val_acc: 0.8085\n",
      "Epoch 64/400\n",
      " - 8s - loss: 0.5115 - acc: 0.8155 - val_loss: 0.5759 - val_acc: 0.8004\n",
      "Epoch 65/400\n",
      " - 8s - loss: 0.5074 - acc: 0.8191 - val_loss: 0.5534 - val_acc: 0.8111\n",
      "Epoch 66/400\n",
      " - 8s - loss: 0.4979 - acc: 0.8222 - val_loss: 0.5636 - val_acc: 0.8103\n",
      "Epoch 67/400\n",
      " - 8s - loss: 0.5015 - acc: 0.8226 - val_loss: 0.5580 - val_acc: 0.8094\n",
      "Epoch 68/400\n",
      " - 8s - loss: 0.5005 - acc: 0.8202 - val_loss: 0.5780 - val_acc: 0.8010\n",
      "Epoch 69/400\n",
      " - 8s - loss: 0.4916 - acc: 0.8264 - val_loss: 0.6146 - val_acc: 0.7916\n",
      "Epoch 70/400\n",
      " - 8s - loss: 0.4946 - acc: 0.8248 - val_loss: 0.5737 - val_acc: 0.8044\n",
      "Epoch 71/400\n",
      " - 8s - loss: 0.4818 - acc: 0.8310 - val_loss: 0.5563 - val_acc: 0.8100\n",
      "Epoch 72/400\n",
      " - 8s - loss: 0.4852 - acc: 0.8269 - val_loss: 0.5625 - val_acc: 0.8061\n",
      "Epoch 73/400\n",
      " - 8s - loss: 0.4806 - acc: 0.8296 - val_loss: 0.5582 - val_acc: 0.8119\n",
      "Epoch 74/400\n",
      " - 8s - loss: 0.4834 - acc: 0.8296 - val_loss: 0.5584 - val_acc: 0.8115\n",
      "Epoch 75/400\n",
      " - 8s - loss: 0.4773 - acc: 0.8294 - val_loss: 0.5627 - val_acc: 0.8083\n",
      "Epoch 76/400\n",
      " - 8s - loss: 0.4817 - acc: 0.8299 - val_loss: 0.5456 - val_acc: 0.8136\n",
      "Epoch 77/400\n",
      " - 8s - loss: 0.4678 - acc: 0.8334 - val_loss: 0.5501 - val_acc: 0.8084\n",
      "Epoch 78/400\n",
      " - 8s - loss: 0.4726 - acc: 0.8324 - val_loss: 0.5522 - val_acc: 0.8123\n",
      "Epoch 79/400\n",
      " - 8s - loss: 0.4609 - acc: 0.8356 - val_loss: 0.5537 - val_acc: 0.8121\n",
      "Epoch 80/400\n",
      " - 8s - loss: 0.4641 - acc: 0.8365 - val_loss: 0.5517 - val_acc: 0.8128\n",
      "Epoch 81/400\n",
      " - 8s - loss: 0.4571 - acc: 0.8362 - val_loss: 0.5518 - val_acc: 0.8121\n",
      "Epoch 82/400\n",
      " - 8s - loss: 0.4623 - acc: 0.8369 - val_loss: 0.5546 - val_acc: 0.8113\n",
      "Epoch 83/400\n",
      " - 8s - loss: 0.4591 - acc: 0.8362 - val_loss: 0.5497 - val_acc: 0.8164\n",
      "Epoch 84/400\n",
      " - 8s - loss: 0.4513 - acc: 0.8379 - val_loss: 0.5535 - val_acc: 0.8119\n",
      "Epoch 85/400\n",
      " - 8s - loss: 0.4490 - acc: 0.8399 - val_loss: 0.5417 - val_acc: 0.8148\n",
      "Epoch 86/400\n",
      " - 8s - loss: 0.4505 - acc: 0.8378 - val_loss: 0.5365 - val_acc: 0.8169\n",
      "Epoch 87/400\n",
      " - 8s - loss: 0.4474 - acc: 0.8404 - val_loss: 0.5319 - val_acc: 0.8209\n",
      "Epoch 88/400\n",
      " - 8s - loss: 0.4460 - acc: 0.8404 - val_loss: 0.5436 - val_acc: 0.8159\n",
      "Epoch 89/400\n",
      " - 8s - loss: 0.4402 - acc: 0.8415 - val_loss: 0.5346 - val_acc: 0.8197\n",
      "Epoch 90/400\n",
      " - 8s - loss: 0.4377 - acc: 0.8430 - val_loss: 0.5440 - val_acc: 0.8176\n",
      "Epoch 91/400\n",
      " - 8s - loss: 0.4376 - acc: 0.8422 - val_loss: 0.5547 - val_acc: 0.8116\n",
      "Epoch 92/400\n",
      " - 8s - loss: 0.4375 - acc: 0.8433 - val_loss: 0.5442 - val_acc: 0.8135\n",
      "Epoch 93/400\n",
      " - 8s - loss: 0.4283 - acc: 0.8471 - val_loss: 0.5423 - val_acc: 0.8183\n",
      "Epoch 94/400\n",
      " - 8s - loss: 0.4346 - acc: 0.8455 - val_loss: 0.5511 - val_acc: 0.8137\n",
      "Epoch 95/400\n",
      " - 8s - loss: 0.4274 - acc: 0.8464 - val_loss: 0.5454 - val_acc: 0.8124\n",
      "Epoch 96/400\n",
      " - 8s - loss: 0.4229 - acc: 0.8488 - val_loss: 0.5440 - val_acc: 0.8182\n",
      "Epoch 97/400\n",
      " - 8s - loss: 0.4256 - acc: 0.8459 - val_loss: 0.5514 - val_acc: 0.8113\n",
      "Epoch 98/400\n",
      " - 8s - loss: 0.4214 - acc: 0.8486 - val_loss: 0.5654 - val_acc: 0.8115\n",
      "Epoch 99/400\n",
      " - 8s - loss: 0.4222 - acc: 0.8476 - val_loss: 0.5452 - val_acc: 0.8163\n",
      "Epoch 100/400\n",
      " - 8s - loss: 0.4168 - acc: 0.8513 - val_loss: 0.5358 - val_acc: 0.8194\n",
      "Epoch 101/400\n",
      " - 8s - loss: 0.4157 - acc: 0.8517 - val_loss: 0.5354 - val_acc: 0.8213\n",
      "Epoch 102/400\n",
      " - 8s - loss: 0.4225 - acc: 0.8488 - val_loss: 0.5502 - val_acc: 0.8164\n",
      "Epoch 103/400\n",
      " - 8s - loss: 0.4129 - acc: 0.8507 - val_loss: 0.5477 - val_acc: 0.8160\n",
      "Epoch 104/400\n",
      " - 8s - loss: 0.4116 - acc: 0.8529 - val_loss: 0.5390 - val_acc: 0.8207\n",
      "Epoch 105/400\n",
      " - 8s - loss: 0.4048 - acc: 0.8552 - val_loss: 0.5472 - val_acc: 0.8172\n",
      "Epoch 106/400\n",
      " - 8s - loss: 0.4049 - acc: 0.8562 - val_loss: 0.5359 - val_acc: 0.8201\n",
      "Epoch 107/400\n",
      " - 8s - loss: 0.4085 - acc: 0.8526 - val_loss: 0.5353 - val_acc: 0.8173\n",
      "Epoch 108/400\n",
      " - 8s - loss: 0.4032 - acc: 0.8560 - val_loss: 0.5268 - val_acc: 0.8239\n",
      "Epoch 109/400\n",
      " - 8s - loss: 0.4080 - acc: 0.8531 - val_loss: 0.5509 - val_acc: 0.8170\n",
      "Epoch 110/400\n",
      " - 8s - loss: 0.4052 - acc: 0.8539 - val_loss: 0.5300 - val_acc: 0.8218\n",
      "Epoch 111/400\n",
      " - 8s - loss: 0.4003 - acc: 0.8566 - val_loss: 0.5310 - val_acc: 0.8234\n",
      "Epoch 112/400\n",
      " - 8s - loss: 0.3948 - acc: 0.8584 - val_loss: 0.5358 - val_acc: 0.8220\n",
      "Epoch 113/400\n",
      " - 8s - loss: 0.3968 - acc: 0.8578 - val_loss: 0.5390 - val_acc: 0.8191\n",
      "Epoch 114/400\n",
      " - 8s - loss: 0.3961 - acc: 0.8566 - val_loss: 0.5357 - val_acc: 0.8223\n",
      "Epoch 115/400\n",
      " - 8s - loss: 0.3971 - acc: 0.8572 - val_loss: 0.5406 - val_acc: 0.8209\n",
      "Epoch 116/400\n",
      " - 8s - loss: 0.3903 - acc: 0.8588 - val_loss: 0.5410 - val_acc: 0.8206\n",
      "Epoch 117/400\n",
      " - 8s - loss: 0.3865 - acc: 0.8614 - val_loss: 0.5328 - val_acc: 0.8260\n",
      "Epoch 118/400\n",
      " - 8s - loss: 0.3844 - acc: 0.8621 - val_loss: 0.5284 - val_acc: 0.8246\n",
      "Epoch 119/400\n",
      " - 8s - loss: 0.3862 - acc: 0.8614 - val_loss: 0.5186 - val_acc: 0.8273\n",
      "Epoch 120/400\n",
      " - 8s - loss: 0.3864 - acc: 0.8613 - val_loss: 0.5310 - val_acc: 0.8252\n",
      "Epoch 121/400\n",
      " - 8s - loss: 0.3873 - acc: 0.8594 - val_loss: 0.5345 - val_acc: 0.8231\n",
      "Epoch 122/400\n",
      " - 8s - loss: 0.3863 - acc: 0.8612 - val_loss: 0.5443 - val_acc: 0.8186\n",
      "Epoch 123/400\n",
      " - 8s - loss: 0.3816 - acc: 0.8635 - val_loss: 0.5403 - val_acc: 0.8197\n",
      "Epoch 124/400\n",
      " - 8s - loss: 0.3740 - acc: 0.8652 - val_loss: 0.5222 - val_acc: 0.8248\n",
      "Epoch 125/400\n",
      " - 8s - loss: 0.3780 - acc: 0.8640 - val_loss: 0.5405 - val_acc: 0.8212\n",
      "Epoch 126/400\n",
      " - 8s - loss: 0.3815 - acc: 0.8632 - val_loss: 0.5317 - val_acc: 0.8240\n",
      "Epoch 127/400\n",
      " - 8s - loss: 0.3784 - acc: 0.8639 - val_loss: 0.5237 - val_acc: 0.8274\n",
      "Epoch 128/400\n",
      " - 8s - loss: 0.3792 - acc: 0.8637 - val_loss: 0.5357 - val_acc: 0.8239\n",
      "Epoch 129/400\n",
      " - 8s - loss: 0.3731 - acc: 0.8650 - val_loss: 0.5318 - val_acc: 0.8250\n",
      "Epoch 130/400\n",
      " - 8s - loss: 0.3728 - acc: 0.8669 - val_loss: 0.5213 - val_acc: 0.8269\n",
      "Epoch 131/400\n",
      " - 8s - loss: 0.3701 - acc: 0.8656 - val_loss: 0.5186 - val_acc: 0.8288\n",
      "Epoch 132/400\n",
      " - 8s - loss: 0.3674 - acc: 0.8682 - val_loss: 0.5161 - val_acc: 0.8288\n",
      "Epoch 133/400\n",
      " - 8s - loss: 0.3609 - acc: 0.8701 - val_loss: 0.5303 - val_acc: 0.8280\n",
      "Epoch 134/400\n",
      " - 8s - loss: 0.3654 - acc: 0.8680 - val_loss: 0.5192 - val_acc: 0.8288\n",
      "Epoch 135/400\n",
      " - 8s - loss: 0.3645 - acc: 0.8690 - val_loss: 0.5130 - val_acc: 0.8275\n",
      "Epoch 136/400\n",
      " - 8s - loss: 0.3630 - acc: 0.8693 - val_loss: 0.5288 - val_acc: 0.8262\n",
      "Epoch 137/400\n",
      " - 8s - loss: 0.3629 - acc: 0.8688 - val_loss: 0.5307 - val_acc: 0.8265\n",
      "Epoch 138/400\n",
      " - 8s - loss: 0.3612 - acc: 0.8691 - val_loss: 0.5293 - val_acc: 0.8247\n",
      "Epoch 139/400\n",
      " - 8s - loss: 0.3635 - acc: 0.8691 - val_loss: 0.5203 - val_acc: 0.8268\n",
      "Epoch 140/400\n",
      " - 8s - loss: 0.3584 - acc: 0.8699 - val_loss: 0.5252 - val_acc: 0.8276\n",
      "Epoch 141/400\n",
      " - 8s - loss: 0.3508 - acc: 0.8745 - val_loss: 0.5261 - val_acc: 0.8279\n",
      "Epoch 142/400\n",
      " - 8s - loss: 0.3598 - acc: 0.8704 - val_loss: 0.5234 - val_acc: 0.8252\n",
      "Epoch 143/400\n",
      " - 8s - loss: 0.3569 - acc: 0.8700 - val_loss: 0.5282 - val_acc: 0.8274\n",
      "Epoch 144/400\n",
      " - 8s - loss: 0.3577 - acc: 0.8732 - val_loss: 0.5152 - val_acc: 0.8300\n",
      "Epoch 145/400\n",
      " - 8s - loss: 0.3534 - acc: 0.8718 - val_loss: 0.5104 - val_acc: 0.8330\n",
      "Epoch 146/400\n",
      " - 8s - loss: 0.3534 - acc: 0.8729 - val_loss: 0.5209 - val_acc: 0.8304\n",
      "Epoch 147/400\n",
      " - 8s - loss: 0.3603 - acc: 0.8700 - val_loss: 0.5226 - val_acc: 0.8290\n",
      "Epoch 148/400\n",
      " - 8s - loss: 0.3496 - acc: 0.8735 - val_loss: 0.5194 - val_acc: 0.8277\n",
      "Epoch 149/400\n",
      " - 8s - loss: 0.3513 - acc: 0.8741 - val_loss: 0.5221 - val_acc: 0.8294\n",
      "Epoch 150/400\n",
      " - 8s - loss: 0.3472 - acc: 0.8747 - val_loss: 0.5305 - val_acc: 0.8260\n",
      "Epoch 151/400\n",
      " - 8s - loss: 0.3466 - acc: 0.8739 - val_loss: 0.5219 - val_acc: 0.8322\n",
      "Epoch 152/400\n",
      " - 8s - loss: 0.3464 - acc: 0.8749 - val_loss: 0.5256 - val_acc: 0.8301\n",
      "Epoch 153/400\n",
      " - 8s - loss: 0.3474 - acc: 0.8739 - val_loss: 0.5278 - val_acc: 0.8288\n",
      "Epoch 154/400\n",
      " - 8s - loss: 0.3443 - acc: 0.8763 - val_loss: 0.5156 - val_acc: 0.8311\n",
      "Epoch 155/400\n",
      " - 8s - loss: 0.3497 - acc: 0.8739 - val_loss: 0.5181 - val_acc: 0.8301\n",
      "Epoch 156/400\n",
      " - 8s - loss: 0.3455 - acc: 0.8756 - val_loss: 0.5209 - val_acc: 0.8291\n",
      "Epoch 157/400\n",
      " - 8s - loss: 0.3439 - acc: 0.8763 - val_loss: 0.5274 - val_acc: 0.8307\n",
      "Epoch 158/400\n",
      " - 8s - loss: 0.3486 - acc: 0.8744 - val_loss: 0.5243 - val_acc: 0.8286\n",
      "Epoch 159/400\n",
      " - 8s - loss: 0.3381 - acc: 0.8773 - val_loss: 0.5257 - val_acc: 0.8258\n",
      "Epoch 160/400\n",
      " - 8s - loss: 0.3369 - acc: 0.8783 - val_loss: 0.5191 - val_acc: 0.8288\n",
      "Epoch 161/400\n",
      " - 8s - loss: 0.3429 - acc: 0.8755 - val_loss: 0.5260 - val_acc: 0.8260\n",
      "Epoch 162/400\n",
      " - 8s - loss: 0.3404 - acc: 0.8779 - val_loss: 0.5174 - val_acc: 0.8280\n",
      "Epoch 163/400\n",
      " - 8s - loss: 0.3422 - acc: 0.8774 - val_loss: 0.5272 - val_acc: 0.8248\n",
      "Epoch 164/400\n",
      " - 8s - loss: 0.3306 - acc: 0.8822 - val_loss: 0.5391 - val_acc: 0.8247\n",
      "Epoch 165/400\n",
      " - 8s - loss: 0.3364 - acc: 0.8799 - val_loss: 0.5177 - val_acc: 0.8294\n",
      "Epoch 166/400\n",
      " - 8s - loss: 0.3376 - acc: 0.8776 - val_loss: 0.5120 - val_acc: 0.8312\n",
      "Epoch 167/400\n",
      " - 8s - loss: 0.3317 - acc: 0.8818 - val_loss: 0.5100 - val_acc: 0.8346\n",
      "Epoch 168/400\n",
      " - 8s - loss: 0.3366 - acc: 0.8786 - val_loss: 0.5039 - val_acc: 0.8391\n",
      "Epoch 169/400\n",
      " - 8s - loss: 0.3299 - acc: 0.8803 - val_loss: 0.5089 - val_acc: 0.8358\n",
      "Epoch 170/400\n",
      " - 8s - loss: 0.3304 - acc: 0.8808 - val_loss: 0.5054 - val_acc: 0.8352\n",
      "Epoch 171/400\n",
      " - 8s - loss: 0.3283 - acc: 0.8814 - val_loss: 0.5360 - val_acc: 0.8274\n",
      "Epoch 172/400\n",
      " - 8s - loss: 0.3277 - acc: 0.8819 - val_loss: 0.5139 - val_acc: 0.8310\n",
      "Epoch 173/400\n",
      " - 8s - loss: 0.3286 - acc: 0.8812 - val_loss: 0.5215 - val_acc: 0.8287\n",
      "Epoch 174/400\n",
      " - 8s - loss: 0.3251 - acc: 0.8835 - val_loss: 0.5267 - val_acc: 0.8291\n",
      "Epoch 175/400\n",
      " - 8s - loss: 0.3327 - acc: 0.8792 - val_loss: 0.5353 - val_acc: 0.8271\n",
      "Epoch 176/400\n",
      " - 8s - loss: 0.3235 - acc: 0.8826 - val_loss: 0.5139 - val_acc: 0.8343\n",
      "Epoch 177/400\n",
      " - 8s - loss: 0.3257 - acc: 0.8835 - val_loss: 0.5205 - val_acc: 0.8318\n",
      "Epoch 178/400\n",
      " - 8s - loss: 0.3237 - acc: 0.8828 - val_loss: 0.5213 - val_acc: 0.8309\n",
      "Epoch 179/400\n",
      " - 8s - loss: 0.3233 - acc: 0.8825 - val_loss: 0.5231 - val_acc: 0.8295\n",
      "Epoch 180/400\n",
      " - 8s - loss: 0.3215 - acc: 0.8839 - val_loss: 0.5276 - val_acc: 0.8280\n",
      "Epoch 181/400\n",
      " - 8s - loss: 0.3221 - acc: 0.8849 - val_loss: 0.5167 - val_acc: 0.8290\n",
      "Epoch 182/400\n",
      " - 8s - loss: 0.3198 - acc: 0.8841 - val_loss: 0.5085 - val_acc: 0.8333\n",
      "Epoch 183/400\n",
      " - 8s - loss: 0.3205 - acc: 0.8841 - val_loss: 0.5180 - val_acc: 0.8323\n",
      "Epoch 184/400\n",
      " - 8s - loss: 0.3214 - acc: 0.8842 - val_loss: 0.5266 - val_acc: 0.8333\n",
      "Epoch 185/400\n",
      " - 8s - loss: 0.3192 - acc: 0.8833 - val_loss: 0.5177 - val_acc: 0.8327\n",
      "Epoch 186/400\n",
      " - 8s - loss: 0.3211 - acc: 0.8857 - val_loss: 0.5223 - val_acc: 0.8291\n",
      "Epoch 187/400\n",
      " - 8s - loss: 0.3147 - acc: 0.8862 - val_loss: 0.5257 - val_acc: 0.8288\n",
      "Epoch 188/400\n",
      " - 8s - loss: 0.3184 - acc: 0.8859 - val_loss: 0.5353 - val_acc: 0.8280\n",
      "Epoch 189/400\n",
      " - 8s - loss: 0.3138 - acc: 0.8855 - val_loss: 0.5209 - val_acc: 0.8328\n",
      "Epoch 190/400\n",
      " - 8s - loss: 0.3169 - acc: 0.8861 - val_loss: 0.5188 - val_acc: 0.8315\n",
      "Epoch 191/400\n",
      " - 8s - loss: 0.3192 - acc: 0.8854 - val_loss: 0.5289 - val_acc: 0.8293\n",
      "Epoch 192/400\n",
      " - 8s - loss: 0.3081 - acc: 0.8886 - val_loss: 0.5304 - val_acc: 0.8294\n",
      "Epoch 193/400\n",
      " - 8s - loss: 0.3139 - acc: 0.8863 - val_loss: 0.5155 - val_acc: 0.8327\n",
      "Epoch 194/400\n",
      " - 8s - loss: 0.3128 - acc: 0.8877 - val_loss: 0.5198 - val_acc: 0.8352\n",
      "Epoch 195/400\n",
      " - 8s - loss: 0.3115 - acc: 0.8874 - val_loss: 0.5220 - val_acc: 0.8344\n",
      "Epoch 196/400\n",
      " - 8s - loss: 0.3150 - acc: 0.8874 - val_loss: 0.5127 - val_acc: 0.8329\n",
      "Epoch 197/400\n",
      " - 8s - loss: 0.3087 - acc: 0.8886 - val_loss: 0.5227 - val_acc: 0.8342\n",
      "Epoch 198/400\n",
      " - 8s - loss: 0.3075 - acc: 0.8892 - val_loss: 0.5266 - val_acc: 0.8324\n",
      "Epoch 199/400\n",
      " - 8s - loss: 0.3121 - acc: 0.8875 - val_loss: 0.5115 - val_acc: 0.8332\n",
      "Epoch 200/400\n",
      " - 8s - loss: 0.3063 - acc: 0.8904 - val_loss: 0.5218 - val_acc: 0.8342\n",
      "Epoch 201/400\n",
      " - 8s - loss: 0.3047 - acc: 0.8886 - val_loss: 0.5160 - val_acc: 0.8368\n",
      "Epoch 202/400\n",
      " - 8s - loss: 0.3077 - acc: 0.8909 - val_loss: 0.5150 - val_acc: 0.8358\n",
      "Epoch 203/400\n",
      " - 8s - loss: 0.3048 - acc: 0.8900 - val_loss: 0.5254 - val_acc: 0.8328\n",
      "Epoch 204/400\n",
      " - 8s - loss: 0.3048 - acc: 0.8906 - val_loss: 0.5381 - val_acc: 0.8260\n",
      "Epoch 205/400\n",
      " - 8s - loss: 0.3091 - acc: 0.8876 - val_loss: 0.5292 - val_acc: 0.8323\n",
      "Epoch 206/400\n",
      " - 8s - loss: 0.3094 - acc: 0.8885 - val_loss: 0.5270 - val_acc: 0.8306\n",
      "Epoch 207/400\n",
      " - 8s - loss: 0.3046 - acc: 0.8902 - val_loss: 0.5304 - val_acc: 0.8332\n",
      "Epoch 208/400\n",
      " - 8s - loss: 0.3061 - acc: 0.8890 - val_loss: 0.5254 - val_acc: 0.8339\n",
      "Epoch 209/400\n",
      " - 8s - loss: 0.3051 - acc: 0.8893 - val_loss: 0.5283 - val_acc: 0.8327\n",
      "Epoch 210/400\n",
      " - 8s - loss: 0.3033 - acc: 0.8906 - val_loss: 0.5259 - val_acc: 0.8333\n",
      "Epoch 211/400\n",
      " - 8s - loss: 0.3039 - acc: 0.8895 - val_loss: 0.5231 - val_acc: 0.8338\n",
      "Epoch 212/400\n",
      " - 8s - loss: 0.3071 - acc: 0.8881 - val_loss: 0.5275 - val_acc: 0.8312\n",
      "Epoch 213/400\n",
      " - 8s - loss: 0.3026 - acc: 0.8898 - val_loss: 0.5213 - val_acc: 0.8349\n",
      "Epoch 214/400\n",
      " - 8s - loss: 0.3024 - acc: 0.8898 - val_loss: 0.5177 - val_acc: 0.8366\n",
      "Epoch 215/400\n",
      " - 8s - loss: 0.2975 - acc: 0.8923 - val_loss: 0.5150 - val_acc: 0.8335\n",
      "Epoch 216/400\n",
      " - 8s - loss: 0.2969 - acc: 0.8924 - val_loss: 0.5201 - val_acc: 0.8343\n",
      "Epoch 217/400\n",
      " - 8s - loss: 0.3006 - acc: 0.8901 - val_loss: 0.5302 - val_acc: 0.8334\n",
      "Epoch 218/400\n",
      " - 8s - loss: 0.2973 - acc: 0.8925 - val_loss: 0.5274 - val_acc: 0.8321\n",
      "Epoch 219/400\n",
      " - 8s - loss: 0.2978 - acc: 0.8920 - val_loss: 0.5355 - val_acc: 0.8306\n",
      "Epoch 220/400\n",
      " - 8s - loss: 0.2973 - acc: 0.8925 - val_loss: 0.5226 - val_acc: 0.8330\n",
      "Epoch 221/400\n",
      " - 8s - loss: 0.2928 - acc: 0.8931 - val_loss: 0.5175 - val_acc: 0.8357\n",
      "Epoch 222/400\n",
      " - 8s - loss: 0.2988 - acc: 0.8904 - val_loss: 0.5108 - val_acc: 0.8364\n",
      "Epoch 223/400\n",
      " - 8s - loss: 0.2934 - acc: 0.8953 - val_loss: 0.5280 - val_acc: 0.8317\n",
      "Epoch 224/400\n",
      " - 8s - loss: 0.2953 - acc: 0.8928 - val_loss: 0.5329 - val_acc: 0.8306\n",
      "Epoch 225/400\n",
      " - 8s - loss: 0.2917 - acc: 0.8924 - val_loss: 0.5178 - val_acc: 0.8374\n",
      "Epoch 226/400\n",
      " - 8s - loss: 0.2920 - acc: 0.8934 - val_loss: 0.5205 - val_acc: 0.8345\n",
      "Epoch 227/400\n",
      " - 8s - loss: 0.2974 - acc: 0.8921 - val_loss: 0.5233 - val_acc: 0.8319\n",
      "Epoch 228/400\n",
      " - 8s - loss: 0.2931 - acc: 0.8939 - val_loss: 0.5234 - val_acc: 0.8349\n",
      "Epoch 229/400\n",
      " - 8s - loss: 0.2943 - acc: 0.8943 - val_loss: 0.5266 - val_acc: 0.8311\n",
      "Epoch 230/400\n",
      " - 8s - loss: 0.2933 - acc: 0.8940 - val_loss: 0.5118 - val_acc: 0.8374\n",
      "Epoch 231/400\n",
      " - 8s - loss: 0.2918 - acc: 0.8937 - val_loss: 0.5292 - val_acc: 0.8325\n",
      "Epoch 232/400\n",
      " - 8s - loss: 0.2936 - acc: 0.8949 - val_loss: 0.5089 - val_acc: 0.8374\n",
      "Epoch 233/400\n",
      " - 8s - loss: 0.2954 - acc: 0.8933 - val_loss: 0.5188 - val_acc: 0.8378\n",
      "Epoch 234/400\n",
      " - 8s - loss: 0.2893 - acc: 0.8962 - val_loss: 0.5171 - val_acc: 0.8339\n",
      "Epoch 235/400\n",
      " - 8s - loss: 0.2866 - acc: 0.8955 - val_loss: 0.5138 - val_acc: 0.8380\n",
      "Epoch 236/400\n",
      " - 8s - loss: 0.2899 - acc: 0.8949 - val_loss: 0.5169 - val_acc: 0.8344\n",
      "Epoch 237/400\n",
      " - 8s - loss: 0.2899 - acc: 0.8960 - val_loss: 0.5184 - val_acc: 0.8359\n",
      "Epoch 238/400\n",
      " - 8s - loss: 0.2890 - acc: 0.8953 - val_loss: 0.5180 - val_acc: 0.8365\n",
      "Epoch 239/400\n",
      " - 8s - loss: 0.2930 - acc: 0.8924 - val_loss: 0.5143 - val_acc: 0.8354\n",
      "Epoch 240/400\n",
      " - 8s - loss: 0.2847 - acc: 0.8961 - val_loss: 0.5167 - val_acc: 0.8356\n",
      "Epoch 241/400\n",
      " - 8s - loss: 0.2833 - acc: 0.8988 - val_loss: 0.5079 - val_acc: 0.8383\n",
      "Epoch 242/400\n",
      " - 8s - loss: 0.2810 - acc: 0.8983 - val_loss: 0.5201 - val_acc: 0.8369\n",
      "Epoch 243/400\n",
      " - 8s - loss: 0.2829 - acc: 0.8980 - val_loss: 0.5226 - val_acc: 0.8358\n",
      "Epoch 244/400\n",
      " - 8s - loss: 0.2818 - acc: 0.8972 - val_loss: 0.5167 - val_acc: 0.8370\n",
      "Epoch 245/400\n",
      " - 8s - loss: 0.2832 - acc: 0.8971 - val_loss: 0.5152 - val_acc: 0.8391\n",
      "Epoch 246/400\n",
      " - 8s - loss: 0.2855 - acc: 0.8960 - val_loss: 0.5203 - val_acc: 0.8347\n",
      "Epoch 247/400\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-a08613ef6cc3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model.fit_generator(datagen.flow(datum[\"x_train\"],datum[\"y_train\"], batch_size=856), epochs=400,\n\u001b[0;32m----> 2\u001b[0;31m           validation_data=(datum[\"x_val\"], datum[\"y_val\"]), verbose=2)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2063\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2064\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2065\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   2066\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2067\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         outs = model.train_on_batch(\n\u001b[0;32m--> 171\u001b[0;31m             x, y, sample_weight=sample_weight, class_weight=class_weight)\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1827\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1828\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1830\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2976\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2977\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 2978\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   2979\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2980\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1397\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1398\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1399\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1400\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit_generator(datagen.flow(datum[\"x_train\"],datum[\"y_train\"], batch_size=856), epochs=400,\n",
    "          validation_data=(datum[\"x_val\"], datum[\"y_val\"]), verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3451
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "GRMvKA4H9xg2",
    "outputId": "5cfb2a42-7bb7-4650-ce09-fc92acf042da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      " - 9s - loss: 0.2748 - acc: 0.9010 - val_loss: 0.5089 - val_acc: 0.8385\n",
      "Epoch 2/100\n",
      " - 8s - loss: 0.2690 - acc: 0.9029 - val_loss: 0.5083 - val_acc: 0.8384\n",
      "Epoch 3/100\n",
      " - 8s - loss: 0.2605 - acc: 0.9043 - val_loss: 0.5039 - val_acc: 0.8393\n",
      "Epoch 4/100\n",
      " - 8s - loss: 0.2638 - acc: 0.9043 - val_loss: 0.5059 - val_acc: 0.8406\n",
      "Epoch 5/100\n",
      " - 8s - loss: 0.2593 - acc: 0.9051 - val_loss: 0.5060 - val_acc: 0.8409\n",
      "Epoch 6/100\n",
      " - 8s - loss: 0.2526 - acc: 0.9080 - val_loss: 0.5041 - val_acc: 0.8412\n",
      "Epoch 7/100\n",
      " - 8s - loss: 0.2618 - acc: 0.9051 - val_loss: 0.5050 - val_acc: 0.8410\n",
      "Epoch 8/100\n",
      " - 8s - loss: 0.2586 - acc: 0.9066 - val_loss: 0.5031 - val_acc: 0.8401\n",
      "Epoch 9/100\n",
      " - 8s - loss: 0.2525 - acc: 0.9087 - val_loss: 0.5043 - val_acc: 0.8394\n",
      "Epoch 10/100\n",
      " - 8s - loss: 0.2546 - acc: 0.9088 - val_loss: 0.5027 - val_acc: 0.8419\n",
      "Epoch 11/100\n",
      " - 8s - loss: 0.2521 - acc: 0.9090 - val_loss: 0.5021 - val_acc: 0.8415\n",
      "Epoch 12/100\n",
      " - 8s - loss: 0.2488 - acc: 0.9093 - val_loss: 0.5038 - val_acc: 0.8400\n",
      "Epoch 13/100\n",
      " - 8s - loss: 0.2543 - acc: 0.9086 - val_loss: 0.5036 - val_acc: 0.8404\n",
      "Epoch 14/100\n",
      " - 8s - loss: 0.2455 - acc: 0.9109 - val_loss: 0.5025 - val_acc: 0.8406\n",
      "Epoch 15/100\n",
      " - 8s - loss: 0.2533 - acc: 0.9078 - val_loss: 0.5038 - val_acc: 0.8418\n",
      "Epoch 16/100\n",
      " - 8s - loss: 0.2534 - acc: 0.9075 - val_loss: 0.5061 - val_acc: 0.8407\n",
      "Epoch 17/100\n",
      " - 8s - loss: 0.2477 - acc: 0.9097 - val_loss: 0.5039 - val_acc: 0.8425\n",
      "Epoch 18/100\n",
      " - 8s - loss: 0.2438 - acc: 0.9124 - val_loss: 0.5034 - val_acc: 0.8425\n",
      "Epoch 19/100\n",
      " - 8s - loss: 0.2481 - acc: 0.9102 - val_loss: 0.5011 - val_acc: 0.8434\n",
      "Epoch 20/100\n",
      " - 8s - loss: 0.2451 - acc: 0.9115 - val_loss: 0.5035 - val_acc: 0.8427\n",
      "Epoch 21/100\n",
      " - 8s - loss: 0.2502 - acc: 0.9095 - val_loss: 0.5019 - val_acc: 0.8420\n",
      "Epoch 22/100\n",
      " - 8s - loss: 0.2433 - acc: 0.9122 - val_loss: 0.5050 - val_acc: 0.8418\n",
      "Epoch 23/100\n",
      " - 8s - loss: 0.2482 - acc: 0.9109 - val_loss: 0.5033 - val_acc: 0.8424\n",
      "Epoch 24/100\n",
      " - 8s - loss: 0.2408 - acc: 0.9132 - val_loss: 0.5025 - val_acc: 0.8415\n",
      "Epoch 25/100\n",
      " - 8s - loss: 0.2477 - acc: 0.9113 - val_loss: 0.5046 - val_acc: 0.8403\n",
      "Epoch 26/100\n",
      " - 8s - loss: 0.2432 - acc: 0.9128 - val_loss: 0.5033 - val_acc: 0.8424\n",
      "Epoch 27/100\n",
      " - 8s - loss: 0.2423 - acc: 0.9124 - val_loss: 0.5046 - val_acc: 0.8403\n",
      "Epoch 28/100\n",
      " - 8s - loss: 0.2369 - acc: 0.9134 - val_loss: 0.5046 - val_acc: 0.8418\n",
      "Epoch 29/100\n",
      " - 8s - loss: 0.2433 - acc: 0.9111 - val_loss: 0.5050 - val_acc: 0.8424\n",
      "Epoch 30/100\n",
      " - 8s - loss: 0.2414 - acc: 0.9137 - val_loss: 0.5052 - val_acc: 0.8427\n",
      "Epoch 31/100\n",
      " - 8s - loss: 0.2377 - acc: 0.9139 - val_loss: 0.5062 - val_acc: 0.8428\n",
      "Epoch 32/100\n",
      " - 8s - loss: 0.2369 - acc: 0.9143 - val_loss: 0.5037 - val_acc: 0.8435\n",
      "Epoch 33/100\n",
      " - 8s - loss: 0.2313 - acc: 0.9165 - val_loss: 0.5044 - val_acc: 0.8442\n",
      "Epoch 34/100\n",
      " - 8s - loss: 0.2384 - acc: 0.9132 - val_loss: 0.5050 - val_acc: 0.8429\n",
      "Epoch 35/100\n",
      " - 8s - loss: 0.2416 - acc: 0.9134 - val_loss: 0.5047 - val_acc: 0.8437\n",
      "Epoch 36/100\n",
      " - 8s - loss: 0.2391 - acc: 0.9122 - val_loss: 0.5048 - val_acc: 0.8435\n",
      "Epoch 37/100\n",
      " - 8s - loss: 0.2364 - acc: 0.9141 - val_loss: 0.5061 - val_acc: 0.8424\n",
      "Epoch 38/100\n",
      " - 8s - loss: 0.2358 - acc: 0.9136 - val_loss: 0.5055 - val_acc: 0.8433\n",
      "Epoch 39/100\n",
      " - 8s - loss: 0.2377 - acc: 0.9132 - val_loss: 0.5059 - val_acc: 0.8439\n",
      "Epoch 40/100\n",
      " - 8s - loss: 0.2368 - acc: 0.9135 - val_loss: 0.5059 - val_acc: 0.8446\n",
      "Epoch 41/100\n",
      " - 8s - loss: 0.2340 - acc: 0.9142 - val_loss: 0.5051 - val_acc: 0.8449\n",
      "Epoch 42/100\n",
      " - 8s - loss: 0.2359 - acc: 0.9142 - val_loss: 0.5067 - val_acc: 0.8444\n",
      "Epoch 43/100\n",
      " - 8s - loss: 0.2364 - acc: 0.9143 - val_loss: 0.5066 - val_acc: 0.8425\n",
      "Epoch 44/100\n",
      " - 8s - loss: 0.2314 - acc: 0.9169 - val_loss: 0.5059 - val_acc: 0.8454\n",
      "Epoch 45/100\n",
      " - 8s - loss: 0.2304 - acc: 0.9172 - val_loss: 0.5060 - val_acc: 0.8443\n",
      "Epoch 46/100\n",
      " - 8s - loss: 0.2345 - acc: 0.9147 - val_loss: 0.5061 - val_acc: 0.8439\n",
      "Epoch 47/100\n",
      " - 8s - loss: 0.2285 - acc: 0.9163 - val_loss: 0.5050 - val_acc: 0.8449\n",
      "Epoch 48/100\n",
      " - 8s - loss: 0.2292 - acc: 0.9161 - val_loss: 0.5053 - val_acc: 0.8454\n",
      "Epoch 49/100\n",
      " - 8s - loss: 0.2282 - acc: 0.9166 - val_loss: 0.5059 - val_acc: 0.8436\n",
      "Epoch 50/100\n",
      " - 8s - loss: 0.2229 - acc: 0.9190 - val_loss: 0.5068 - val_acc: 0.8454\n",
      "Epoch 51/100\n",
      " - 8s - loss: 0.2321 - acc: 0.9164 - val_loss: 0.5079 - val_acc: 0.8435\n",
      "Epoch 52/100\n",
      " - 8s - loss: 0.2253 - acc: 0.9186 - val_loss: 0.5071 - val_acc: 0.8444\n",
      "Epoch 53/100\n",
      " - 8s - loss: 0.2284 - acc: 0.9169 - val_loss: 0.5096 - val_acc: 0.8434\n",
      "Epoch 54/100\n",
      " - 8s - loss: 0.2258 - acc: 0.9173 - val_loss: 0.5091 - val_acc: 0.8443\n",
      "Epoch 55/100\n",
      " - 8s - loss: 0.2254 - acc: 0.9185 - val_loss: 0.5069 - val_acc: 0.8437\n",
      "Epoch 56/100\n",
      " - 8s - loss: 0.2289 - acc: 0.9169 - val_loss: 0.5073 - val_acc: 0.8441\n",
      "Epoch 57/100\n",
      " - 8s - loss: 0.2256 - acc: 0.9177 - val_loss: 0.5091 - val_acc: 0.8433\n",
      "Epoch 58/100\n",
      " - 8s - loss: 0.2261 - acc: 0.9176 - val_loss: 0.5072 - val_acc: 0.8443\n",
      "Epoch 59/100\n",
      " - 8s - loss: 0.2248 - acc: 0.9184 - val_loss: 0.5066 - val_acc: 0.8442\n",
      "Epoch 60/100\n",
      " - 8s - loss: 0.2307 - acc: 0.9154 - val_loss: 0.5076 - val_acc: 0.8436\n",
      "Epoch 61/100\n",
      " - 8s - loss: 0.2245 - acc: 0.9192 - val_loss: 0.5087 - val_acc: 0.8448\n",
      "Epoch 62/100\n",
      " - 8s - loss: 0.2273 - acc: 0.9167 - val_loss: 0.5075 - val_acc: 0.8443\n",
      "Epoch 63/100\n",
      " - 8s - loss: 0.2249 - acc: 0.9178 - val_loss: 0.5087 - val_acc: 0.8440\n",
      "Epoch 64/100\n",
      " - 8s - loss: 0.2218 - acc: 0.9177 - val_loss: 0.5062 - val_acc: 0.8448\n",
      "Epoch 65/100\n",
      " - 8s - loss: 0.2208 - acc: 0.9192 - val_loss: 0.5089 - val_acc: 0.8453\n",
      "Epoch 66/100\n",
      " - 8s - loss: 0.2295 - acc: 0.9167 - val_loss: 0.5078 - val_acc: 0.8438\n",
      "Epoch 67/100\n",
      " - 8s - loss: 0.2186 - acc: 0.9213 - val_loss: 0.5087 - val_acc: 0.8441\n",
      "Epoch 68/100\n",
      " - 8s - loss: 0.2252 - acc: 0.9189 - val_loss: 0.5076 - val_acc: 0.8446\n",
      "Epoch 69/100\n",
      " - 8s - loss: 0.2238 - acc: 0.9183 - val_loss: 0.5070 - val_acc: 0.8444\n",
      "Epoch 70/100\n",
      " - 8s - loss: 0.2211 - acc: 0.9201 - val_loss: 0.5069 - val_acc: 0.8431\n",
      "Epoch 71/100\n",
      " - 8s - loss: 0.2231 - acc: 0.9199 - val_loss: 0.5097 - val_acc: 0.8442\n",
      "Epoch 72/100\n",
      " - 8s - loss: 0.2209 - acc: 0.9199 - val_loss: 0.5083 - val_acc: 0.8448\n",
      "Epoch 73/100\n",
      " - 8s - loss: 0.2193 - acc: 0.9201 - val_loss: 0.5078 - val_acc: 0.8437\n",
      "Epoch 74/100\n",
      " - 8s - loss: 0.2155 - acc: 0.9229 - val_loss: 0.5124 - val_acc: 0.8448\n",
      "Epoch 75/100\n",
      " - 8s - loss: 0.2203 - acc: 0.9193 - val_loss: 0.5082 - val_acc: 0.8442\n",
      "Epoch 76/100\n",
      " - 8s - loss: 0.2221 - acc: 0.9190 - val_loss: 0.5078 - val_acc: 0.8439\n",
      "Epoch 77/100\n",
      " - 8s - loss: 0.2202 - acc: 0.9201 - val_loss: 0.5084 - val_acc: 0.8448\n",
      "Epoch 78/100\n",
      " - 8s - loss: 0.2193 - acc: 0.9207 - val_loss: 0.5107 - val_acc: 0.8452\n",
      "Epoch 79/100\n",
      " - 8s - loss: 0.2131 - acc: 0.9223 - val_loss: 0.5113 - val_acc: 0.8445\n",
      "Epoch 80/100\n",
      " - 8s - loss: 0.2188 - acc: 0.9206 - val_loss: 0.5096 - val_acc: 0.8461\n",
      "Epoch 81/100\n",
      " - 8s - loss: 0.2184 - acc: 0.9201 - val_loss: 0.5099 - val_acc: 0.8438\n",
      "Epoch 82/100\n",
      " - 8s - loss: 0.2171 - acc: 0.9216 - val_loss: 0.5102 - val_acc: 0.8452\n",
      "Epoch 83/100\n",
      " - 8s - loss: 0.2169 - acc: 0.9215 - val_loss: 0.5126 - val_acc: 0.8440\n",
      "Epoch 84/100\n",
      " - 8s - loss: 0.2159 - acc: 0.9212 - val_loss: 0.5110 - val_acc: 0.8434\n",
      "Epoch 85/100\n",
      " - 8s - loss: 0.2207 - acc: 0.9203 - val_loss: 0.5121 - val_acc: 0.8452\n",
      "Epoch 86/100\n",
      " - 8s - loss: 0.2182 - acc: 0.9228 - val_loss: 0.5104 - val_acc: 0.8459\n",
      "Epoch 87/100\n",
      " - 8s - loss: 0.2154 - acc: 0.9206 - val_loss: 0.5109 - val_acc: 0.8458\n",
      "Epoch 88/100\n",
      " - 8s - loss: 0.2183 - acc: 0.9208 - val_loss: 0.5126 - val_acc: 0.8452\n",
      "Epoch 89/100\n",
      " - 8s - loss: 0.2144 - acc: 0.9220 - val_loss: 0.5119 - val_acc: 0.8447\n",
      "Epoch 90/100\n",
      " - 8s - loss: 0.2125 - acc: 0.9230 - val_loss: 0.5120 - val_acc: 0.8450\n",
      "Epoch 91/100\n",
      " - 8s - loss: 0.2180 - acc: 0.9215 - val_loss: 0.5137 - val_acc: 0.8457\n",
      "Epoch 92/100\n",
      " - 8s - loss: 0.2165 - acc: 0.9212 - val_loss: 0.5113 - val_acc: 0.8442\n",
      "Epoch 93/100\n",
      " - 8s - loss: 0.2180 - acc: 0.9205 - val_loss: 0.5129 - val_acc: 0.8454\n",
      "Epoch 94/100\n",
      " - 8s - loss: 0.2132 - acc: 0.9221 - val_loss: 0.5114 - val_acc: 0.8450\n",
      "Epoch 95/100\n",
      " - 8s - loss: 0.2109 - acc: 0.9233 - val_loss: 0.5111 - val_acc: 0.8450\n",
      "Epoch 96/100\n",
      " - 8s - loss: 0.2185 - acc: 0.9217 - val_loss: 0.5104 - val_acc: 0.8451\n",
      "Epoch 97/100\n",
      " - 8s - loss: 0.2150 - acc: 0.9216 - val_loss: 0.5119 - val_acc: 0.8455\n",
      "Epoch 98/100\n",
      " - 8s - loss: 0.2096 - acc: 0.9244 - val_loss: 0.5117 - val_acc: 0.8451\n",
      "Epoch 99/100\n",
      " - 8s - loss: 0.2153 - acc: 0.9228 - val_loss: 0.5119 - val_acc: 0.8448\n",
      "Epoch 100/100\n",
      " - 8s - loss: 0.2112 - acc: 0.9234 - val_loss: 0.5146 - val_acc: 0.8458\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f3954e3f4e0>"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=keras.optimizers.SGD(1e-2, momentum=0.7),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(datum[\"x_train\"],datum[\"y_train\"], batch_size=856, epochs=100,\n",
    "          validation_data=(datum[\"x_val\"], datum[\"y_val\"]), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yGv26-HOqQE8"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.SGD(1e-3, momentum=0.7),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(datum[\"x_train\"],datum[\"y_train\"], batch_size=856, epochs=100,\n",
    "          validation_data=(datum[\"x_val\"], datum[\"y_val\"]), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "O7__xiLbWb2a",
    "outputId": "3b4c8b99-c420-4168-a3d3-c966a604b4e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 137us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5208640723586082, 0.8408]"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(datum[\"x_test\"],datum[\"y_test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l2cVS9F2Wb2f"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Pedoeem_HW4-Cifar10.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
