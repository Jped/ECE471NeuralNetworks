{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "tf.set_random_seed(1234)\n",
    "IMAGE_HEIGHT = 28\n",
    "IMAGE_WIDTH  = 28\n",
    "batch_size = 20\n",
    "NUM_CLASSES = 10\n",
    "l2_lamb = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape(x):\n",
    "    return np.reshape(x, [-1,IMAGE_WIDTH,IMAGE_HEIGHT,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mnist():\n",
    "    datum = {}\n",
    "    mnist = tf.keras.datasets.mnist\n",
    "    (x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "    x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "    randos = np.random.choice(60000,60000)\n",
    "    validation_randos = randos[:12000]\n",
    "    train_randos = randos[12000:]\n",
    "    val_x, val_y = reshape(x_train[validation_randos]), y_train[validation_randos]\n",
    "    x_train, y_train = reshape(x_train[train_randos]), y_train[train_randos]\n",
    "    x_test = reshape(x_test)\n",
    "    y_train = keras.utils.to_categorical(y_train, NUM_CLASSES)\n",
    "    y_test = keras.utils.to_categorical(y_test, NUM_CLASSES)\n",
    "    val_y = keras.utils.to_categorical(val_y,NUM_CLASSES)\n",
    "    datum = {\"x_train\":x_train, \"y_train\":y_train, \"x_val\":val_x, \"y_val\":val_y,\"x_test\":x_test,\"y_test\":y_test}\n",
    "    return datum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "datum = get_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Conv2D(filters=2,kernel_size=(4,4),strides=2,padding='valid',activation='elu'))\n",
    "model.add(keras.layers.MaxPool2D(pool_size=(3,3)))\n",
    "model.add(keras.layers.Conv2D(filters=1,kernel_size=(2,2),strides=1,padding='valid',activation='elu'))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(NUM_CLASSES,activation=\"softmax\"))\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(0.01),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/200\n",
      " - 8s - loss: 1.4776 - acc: 0.4686 - val_loss: 1.0665 - val_acc: 0.6252\n",
      "Epoch 2/200\n",
      " - 3s - loss: 1.0056 - acc: 0.6496 - val_loss: 0.9495 - val_acc: 0.6772\n",
      "Epoch 3/200\n",
      " - 3s - loss: 0.9287 - acc: 0.6853 - val_loss: 0.8902 - val_acc: 0.7013\n",
      "Epoch 4/200\n",
      " - 3s - loss: 0.8945 - acc: 0.7003 - val_loss: 0.8711 - val_acc: 0.7080\n",
      "Epoch 5/200\n",
      " - 4s - loss: 0.8773 - acc: 0.7078 - val_loss: 0.8519 - val_acc: 0.7147\n",
      "Epoch 6/200\n",
      " - 3s - loss: 0.8670 - acc: 0.7124 - val_loss: 0.8482 - val_acc: 0.7232\n",
      "Epoch 7/200\n",
      " - 3s - loss: 0.8593 - acc: 0.7191 - val_loss: 0.8438 - val_acc: 0.7219\n",
      "Epoch 8/200\n",
      " - 3s - loss: 0.8488 - acc: 0.7259 - val_loss: 0.8222 - val_acc: 0.7344\n",
      "Epoch 9/200\n",
      " - 3s - loss: 0.8382 - acc: 0.7311 - val_loss: 0.8089 - val_acc: 0.7407\n",
      "Epoch 10/200\n",
      " - 3s - loss: 0.8254 - acc: 0.7367 - val_loss: 0.7987 - val_acc: 0.7437\n",
      "Epoch 11/200\n",
      " - 3s - loss: 0.8083 - acc: 0.7436 - val_loss: 0.7854 - val_acc: 0.7483\n",
      "Epoch 12/200\n",
      " - 3s - loss: 0.7885 - acc: 0.7489 - val_loss: 0.7684 - val_acc: 0.7567\n",
      "Epoch 13/200\n",
      " - 3s - loss: 0.7620 - acc: 0.7580 - val_loss: 0.7360 - val_acc: 0.7718\n",
      "Epoch 14/200\n",
      " - 3s - loss: 0.7257 - acc: 0.7678 - val_loss: 0.7104 - val_acc: 0.7775\n",
      "Epoch 15/200\n",
      " - 3s - loss: 0.6919 - acc: 0.7775 - val_loss: 0.6913 - val_acc: 0.7811\n",
      "Epoch 16/200\n",
      " - 3s - loss: 0.6571 - acc: 0.7858 - val_loss: 0.6475 - val_acc: 0.7940\n",
      "Epoch 17/200\n",
      " - 4s - loss: 0.6193 - acc: 0.7986 - val_loss: 0.6146 - val_acc: 0.8056\n",
      "Epoch 18/200\n",
      " - 4s - loss: 0.5818 - acc: 0.8141 - val_loss: 0.5772 - val_acc: 0.8182\n",
      "Epoch 19/200\n",
      " - 3s - loss: 0.5426 - acc: 0.8285 - val_loss: 0.5313 - val_acc: 0.8344\n",
      "Epoch 20/200\n",
      " - 4s - loss: 0.5136 - acc: 0.8366 - val_loss: 0.5138 - val_acc: 0.8347\n",
      "Epoch 21/200\n",
      " - 4s - loss: 0.4939 - acc: 0.8440 - val_loss: 0.5008 - val_acc: 0.8411\n",
      "Epoch 22/200\n",
      " - 3s - loss: 0.4839 - acc: 0.8473 - val_loss: 0.4869 - val_acc: 0.8438\n",
      "Epoch 23/200\n",
      " - 3s - loss: 0.4772 - acc: 0.8496 - val_loss: 0.4936 - val_acc: 0.8392\n",
      "Epoch 24/200\n",
      " - 3s - loss: 0.4732 - acc: 0.8518 - val_loss: 0.4754 - val_acc: 0.8451\n",
      "Epoch 25/200\n",
      " - 3s - loss: 0.4706 - acc: 0.8517 - val_loss: 0.4716 - val_acc: 0.8453\n",
      "Epoch 26/200\n",
      " - 3s - loss: 0.4683 - acc: 0.8515 - val_loss: 0.4750 - val_acc: 0.8448\n",
      "Epoch 27/200\n",
      " - 3s - loss: 0.4714 - acc: 0.8514 - val_loss: 0.4690 - val_acc: 0.8488\n",
      "Epoch 28/200\n",
      " - 3s - loss: 0.4643 - acc: 0.8543 - val_loss: 0.4757 - val_acc: 0.8436\n",
      "Epoch 29/200\n",
      " - 3s - loss: 0.4644 - acc: 0.8523 - val_loss: 0.4671 - val_acc: 0.8485\n",
      "Epoch 30/200\n",
      " - 3s - loss: 0.4657 - acc: 0.8528 - val_loss: 0.4678 - val_acc: 0.8461\n",
      "Epoch 31/200\n",
      " - 3s - loss: 0.4631 - acc: 0.8539 - val_loss: 0.4657 - val_acc: 0.8482\n",
      "Epoch 32/200\n",
      " - 3s - loss: 0.4643 - acc: 0.8526 - val_loss: 0.4669 - val_acc: 0.8486\n",
      "Epoch 33/200\n",
      " - 3s - loss: 0.4639 - acc: 0.8530 - val_loss: 0.4663 - val_acc: 0.8484\n",
      "Epoch 34/200\n",
      " - 3s - loss: 0.4635 - acc: 0.8519 - val_loss: 0.4670 - val_acc: 0.8470\n",
      "Epoch 35/200\n",
      " - 3s - loss: 0.4634 - acc: 0.8533 - val_loss: 0.4718 - val_acc: 0.8443\n",
      "Epoch 36/200\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-500-3dba472c2c61>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtensorboard\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensorBoard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"logs/{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m model.fit(datum[\"x_train\"],datum[\"y_train\"], epochs=200, batch_size=256,\n\u001b[1;32m----> 3\u001b[1;33m           validation_data=(datum[\"x_val\"], datum[\"y_val\"]), verbose=2, callbacks=[tensorboard])\n\u001b[0m",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1346\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1347\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1348\u001b[1;33m           validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1350\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    251\u001b[0m           \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 253\u001b[1;33m         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    254\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m           \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2881\u001b[0m         \u001b[1;31m# We need to do array conversion and type casting at this level, since\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2882\u001b[0m         \u001b[1;31m# `callable_fn` only supports exact matches.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2883\u001b[1;33m         \u001b[0marray_vals\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2884\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2885\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    490\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m     \"\"\"\n\u001b[1;32m--> 492\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    493\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tensorboard = tf.keras.callbacks.TensorBoard(log_dir=\"logs/{}\".format(time()))\n",
    "model.fit(datum[\"x_train\"],datum[\"y_train\"], epochs=200, batch_size=256,\n",
    "          validation_data=(datum[\"x_val\"], datum[\"y_val\"]), verbose=2, callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143\n",
      "[None, 13, 13, 2]\n",
      "[None, 4, 4, 2]\n",
      "[None, 3, 3, 1]\n",
      "[None, 9]\n",
      "[None, 10]\n"
     ]
    }
   ],
   "source": [
    "print(model.count_params())\n",
    "for layer in model.layers:\n",
    "    print(layer.get_output_at(0).get_shape().as_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 2s 202us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.45329682639837265, 0.8576]"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(datum[\"x_test\"],datum[\"y_test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
